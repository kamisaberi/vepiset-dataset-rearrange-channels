{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-06T18:08:29.544651Z",
     "start_time": "2025-05-06T18:08:27.712035Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import numpy as np\n",
    "from easydict import EasyDict as edict\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import setproctitle\n",
    "import random\n",
    "import copy\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import os\n",
    "# from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from timm.loss.binary_cross_entropy import BinaryCrossEntropy\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import timm\n",
    "import random\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T18:08:30.283249Z",
     "start_time": "2025-05-06T18:08:30.280972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "setproctitle.setproctitle(\"spike_train\")\n",
    "sys.path.append('.')\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "50c0ef71c6141ad8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T18:08:30.512092Z",
     "start_time": "2025-05-06T18:08:30.510106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "numpy_files_path = \"/run/media/kami/SSD/DATASETS/vepiset-dataset/NPY-Files/\"\n",
    "save_csv_file = \"./data.csv\""
   ],
   "id": "77a3edfef6009abb",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Configuration",
   "id": "35a4b5e7c71cb5d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T18:08:31.251299Z",
     "start_time": "2025-05-06T18:08:31.249365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)  # cpu\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n"
   ],
   "id": "7bc5937304439022",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T18:08:33.960535Z",
     "start_time": "2025-05-06T18:08:33.954841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = edict()\n",
    "\n",
    "config.TRAIN = edict()\n",
    "\n",
    "config.TRAIN.process_num = 1\n",
    "\n",
    "config.TRAIN.batch_size = 128\n",
    "config.TRAIN.validatiojn_batch_size = config.TRAIN.batch_size\n",
    "config.TRAIN.accumulation_batch_size = 128\n",
    "config.TRAIN.log_interval = 10\n",
    "config.TRAIN.test_interval = 1\n",
    "config.TRAIN.epoch = 1\n",
    "\n",
    "config.TRAIN.init_lr = 0.0005\n",
    "config.TRAIN.lr_scheduler = 'cos'\n",
    "\n",
    "if config.TRAIN.lr_scheduler == 'ReduceLROnPlateau':\n",
    "    config.TRAIN.epoch = 1\n",
    "    config.TRAIN.lr_scheduler_factor = 0.1\n",
    "\n",
    "config.TRAIN.weight_decay_factor = 1.e-2\n",
    "config.TRAIN.vis = False\n",
    "\n",
    "config.TRAIN.warmup_step = 1500\n",
    "config.TRAIN.opt = 'Adamw'\n",
    "\n",
    "config.TRAIN.gradient_clip = 5\n",
    "\n",
    "config.TRAIN.vis_mixcut = False\n",
    "if config.TRAIN.vis:\n",
    "    config.TRAIN.mix_precision = False\n",
    "else:\n",
    "    config.TRAIN.mix_precision = False\n",
    "\n",
    "config.MODEL = edict()\n",
    "\n",
    "config.MODEL.model_path = './trained_models/'\n",
    "# config.MODEL.model_path = '/run/media/kami/SSD/DATASETS/vepiset-dataset/Test_Mat'\n",
    "# config.MODEL.model_path = 'E:\\\\DATASETS\\\\vepiset-dataset\\\\Test_Mat'\n",
    "\n",
    "config.DATA = edict()\n",
    "\n",
    "config.DATA.data_file = save_csv_file\n",
    "# config.DATA.data_file = \"/run/media/kami/SSD/DATASETS/vepiset-dataset/CSV-Files/data.csv\"\n",
    "# config.DATA.data_file = \"E:\\\\DATASETS\\\\vepiset-dataset\\\\CSV-Files\\\\data.csv\"\n",
    "\n",
    "config.DATA.data_root_path = 'utils'\n",
    "\n",
    "config.MODEL.early_stop = 30\n",
    "\n",
    "config.MODEL.pretrained_model = None\n",
    "\n",
    "config.SEED = 10086\n",
    "\n",
    "seed_everything(config.SEED)\n",
    "config.is_base = 1\n"
   ],
   "id": "4abea7a354f85044",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Create CSV File From NPY Files",
   "id": "c040671250bbcfdd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Variables",
   "id": "8eb2b1a54addd6c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T18:08:34.921040Z",
     "start_time": "2025-05-06T18:08:34.919350Z"
    }
   },
   "cell_type": "code",
   "source": "\n",
   "id": "640dbe47f11e7b66",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T18:08:35.226062Z",
     "start_time": "2025-05-06T18:08:35.223578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_npy_files(folder_path):\n",
    "    npy_files = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.npy'):\n",
    "                npy_files.append(os.path.join(root, file))\n",
    "\n",
    "    return npy_files\n",
    "\n",
    "\n",
    "def get_data(data_dir):\n",
    "    samples = find_npy_files(data_dir)\n",
    "    labels = [1 if int(x.split(\"__\")[1].split(\".\")[0]) > 1 else int(x.split(\"__\")[1].split(\".\")[0]) for x in samples]\n",
    "    train_val = [0] * len(samples)\n",
    "    return samples, labels, train_val\n",
    "\n",
    "\n",
    "def get_data_files(numpy_files_path):\n",
    "    #data_dir = npy_val_data\n",
    "    fns_list = []\n",
    "    labels_list = []\n",
    "    train_val_list = []\n",
    "    samples, labels, train_val = get_data(numpy_files_path)\n",
    "    fns_list.extend(samples)\n",
    "    labels_list.extend(labels)\n",
    "    train_val_list.extend(train_val)\n",
    "    # print(\"train_val_list\" , train_val_list)\n",
    "    return fns_list, labels_list, train_val_list\n"
   ],
   "id": "8852bd9026067bf",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T18:08:38.095696Z",
     "start_time": "2025-05-06T18:08:38.024303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val_fns_list, val_labels_list, val_vals_list = get_data_files(numpy_files_path)\n",
    "# print(val_fns_list)\n",
    "# print( val_labels_list)\n",
    "# print( val_vals_list)\n",
    "submission = pd.DataFrame({'file_path': val_fns_list,\n",
    "                           'target': val_labels_list,\n",
    "                           'train_val': val_vals_list})\n",
    "# submission\n",
    "### split train - val = 8:2\n",
    "indices = submission[submission['train_val'] == 0].index\n",
    "val_num = len(indices) // 5\n",
    "indices_to_change = np.random.choice(indices, val_num, replace=False)\n",
    "submission.loc[indices_to_change, 'train_val'] = 1\n",
    "\n",
    "# print(\"fns len:\", len(val_fns_list))\n",
    "# print(\"label len:\", len(val_labels_list))\n",
    "# print(\"val len:\", val_num)\n",
    "# print(\"train:val {0}:{1}\".format(8, 2))\n",
    "submission.to_csv(save_csv_file, index=False)\n",
    "# submission\n",
    "# submission.head()\n"
   ],
   "id": "12b614367629b6ba",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Train",
   "id": "f61cc0f557fde3d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T18:08:38.882658Z",
     "start_time": "2025-05-06T18:08:38.880470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_logger(LEVEL, log_file=None):\n",
    "    head = '[%(asctime)-15s] [%(levelname)s] %(message)s '\n",
    "    if LEVEL == 'info':\n",
    "        logging.basicConfig(level=logging.INFO, format=head)\n",
    "    elif LEVEL == 'debug':\n",
    "        logging.basicConfig(level=logging.DEBUG, format=head)\n",
    "    logger = logging.getLogger()\n",
    "\n",
    "    if log_file != None:\n",
    "        fh = logging.FileHandler(log_file)\n",
    "        logger.addHandler(fh)\n",
    "    return logger\n",
    "\n",
    "\n",
    "logger = get_logger('info')\n"
   ],
   "id": "44216f31eafd00b0",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T18:08:42.264327Z",
     "start_time": "2025-05-06T18:08:42.256879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AUG(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs = x.size(0)\n",
    "        for i in range(bs):\n",
    "            if random.uniform(0, 1) < 0.5:\n",
    "                x[i, ...] = self.pitch_shift_spectrogram(x[i, ...])\n",
    "            if random.uniform(0, 1) < 0.0:\n",
    "                x[i, ...] = self.time_shift_spectrogram(x[i, ...])\n",
    "\n",
    "        return x\n",
    "\n",
    "    def do_cut_out(self, x):\n",
    "\n",
    "        h = 128\n",
    "        w = 128\n",
    "        line_width = random.randint(1, 8)\n",
    "\n",
    "        if random.uniform(0, 1) < 0.5:\n",
    "\n",
    "            start = random.randint(0, w - line_width)\n",
    "            x[:, :, start:start + line_width] = 0\n",
    "        else:\n",
    "            start = random.randint(0, h - line_width)\n",
    "            x[:, start:start + line_width, :] = 0\n",
    "\n",
    "        return x\n",
    "\n",
    "    def pitch_shift_spectrogram(self, spectrogram):\n",
    "        \"\"\" Shift a spectrogram along the frequency axis in the spectral-domain at\n",
    "        random\n",
    "        \"\"\"\n",
    "        nb_cols = spectrogram.size(1)\n",
    "        max_shifts = nb_cols // 50  # around 5% shift\n",
    "        nb_shifts = random.randint(-max_shifts, max_shifts)\n",
    "\n",
    "        return torch.roll(spectrogram, nb_shifts, dims=[1])\n",
    "\n",
    "    def time_shift_spectrogram(self, spectrogram):\n",
    "        \"\"\" Shift a spectrogram along the frequency axis in the spectral-domain at\n",
    "        random\n",
    "        \"\"\"\n",
    "        nb_cols = spectrogram.size(2)\n",
    "        max_shifts = nb_cols // 2  # around 100% shift\n",
    "        nb_shifts = random.randint(-max_shifts, max_shifts)\n",
    "\n",
    "        return torch.roll(spectrogram, nb_shifts, dims=[2])\n",
    "\n",
    "\n",
    "class Transform(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "        self.wave_transform = torchaudio.transforms.Spectrogram(n_fft=256, hop_length=16, power=1, pad_mode='reflect')\n",
    "\n",
    "    def forward(self, x):\n",
    "        image = self.wave_transform(x)\n",
    "        return image\n",
    "\n",
    "\n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, feature_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(feature_size, 6)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.linear2 = nn.Linear(6, 24)\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.linear3 = nn.Linear(24, 24)\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.linear3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=1, add_channel=0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.preprocess = Transform()\n",
    "\n",
    "        self.model = timm.create_model('vgg16',\n",
    "                                       pretrained=True,\n",
    "                                       in_chans=45)\n",
    "\n",
    "        self.avg_pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(512, num_classes, bias=True)\n",
    "        self.add_sleep_feature = MLP(1)\n",
    "        weight_init(self.fc)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # do preprocess\n",
    "        bs = x.size(0)\n",
    "        x = self.preprocess(x)\n",
    "        x = self.model.forward_features(x)\n",
    "        fm = self.avg_pooling(x)\n",
    "        fm = fm.view(bs, -1)\n",
    "        feature = self.dropout(fm)\n",
    "        x = self.fc(feature)\n",
    "\n",
    "        return x\n"
   ],
   "id": "c7a8e8e5cd9a43c3",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T18:44:20.063730Z",
     "start_time": "2025-05-06T18:44:20.056799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AlaskaDataIter():\n",
    "    def __init__(self, df,\n",
    "                 training_flag=True, shuffle=True):\n",
    "\n",
    "        self.training_flag = training_flag\n",
    "        self.shuffle = shuffle\n",
    "        self.raw_data_set_size = None\n",
    "\n",
    "        self.df = df\n",
    "        logger.info(' contains%d samples  %d pos' % (len(self.df), np.sum(self.df['target'] == 1)))\n",
    "        logger.info(' contains%d samples' % len(self.df))\n",
    "\n",
    "        logger.info(' After filter contains%d samples  %d pos' % (len(self.df), np.sum(self.df['target'] == 1)))\n",
    "        logger.info(' After filter contains%d samples' % len(self.df))\n",
    "\n",
    "        self.leads_nm = ['Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2', 'F7', 'F8', 'T3', 'T4', 'T5',\n",
    "                         'T6',\n",
    "                         'Fz', 'Cz', 'Pz',\n",
    "                         'PG1', 'PG2', 'A1', 'A2',\n",
    "                         'ECG1', 'ECG2', 'EMG1',\n",
    "                         'EMG2', 'EMG3', 'EMG4']\n",
    "\n",
    "        self.leads_dict = {value: index for index, value in enumerate(self.leads_nm)}\n",
    "\n",
    "        self.left_brain = ['Fp1', 'F3', 'C3', 'P3', 'O1', 'T5', 'T3', 'F7']\n",
    "        self.right_brain = ['Fp2', 'F4', 'C4', 'P4', 'O2', 'T6', 'T4', 'F8']\n",
    "\n",
    "    def filter(self, df):\n",
    "\n",
    "        df = copy.deepcopy(df)\n",
    "        pos_indx = df['target'] == 1\n",
    "        pos_df = df[pos_indx]\n",
    "\n",
    "        neg_indx = df['target'] == 0\n",
    "        neg_df = df[neg_indx]\n",
    "\n",
    "        neg_df = neg_df.sample(frac=1)\n",
    "\n",
    "        dst_df = neg_df\n",
    "        for i in range(1):\n",
    "            dst_df = dst_df._append(pos_df)\n",
    "        dst_df.reset_index()\n",
    "\n",
    "        return dst_df\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.single_map_func(self.df.iloc[item], self.training_flag)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def norm(self, wave):\n",
    "\n",
    "        wave[:23, ...] = wave[:23, ...] / 1e-3\n",
    "        wave[23:, ...] = wave[23:, ...] / 1e-2\n",
    "\n",
    "        # 心电和肌电\n",
    "        heart_wave = wave[23, :] - wave[24, :]\n",
    "\n",
    "        muscle_wave1 = wave[25, :] - wave[26, :]\n",
    "\n",
    "        muscle_wave2 = wave[27, :] - wave[28, :]\n",
    "\n",
    "        heart_muscle = np.stack([heart_wave, muscle_wave1, muscle_wave2], axis=0)\n",
    "\n",
    "        wave_26 = np.concatenate([wave[:23, ...], heart_muscle], axis=0)\n",
    "\n",
    "        return wave_26\n",
    "\n",
    "    def roll(self, waves, strength=2000 // 2):\n",
    "\n",
    "        start = random.randint(-strength, strength)\n",
    "        waves = np.roll(waves, start, axis=1)\n",
    "\n",
    "        return waves\n",
    "\n",
    "    def xshuffle(self, wave):\n",
    "\n",
    "        n_channels, n_samples = wave.shape\n",
    "\n",
    "        channel_indices = np.arange(n_channels)\n",
    "\n",
    "        np.random.shuffle(channel_indices)\n",
    "\n",
    "        shuffled_wave = wave[channel_indices]\n",
    "\n",
    "        return shuffled_wave\n",
    "\n",
    "    def avg_lead(self, waves):\n",
    "\n",
    "        # copy一份，防止原地修改\n",
    "        waves = copy.deepcopy(waves)\n",
    "\n",
    "        meadn = np.mean(waves[:19, :], axis=0)\n",
    "        data = waves[:19, :] - meadn\n",
    "        return data\n",
    "\n",
    "    def lead(self, waves):\n",
    "\n",
    "        avg_lead = self.avg_lead(waves)\n",
    "\n",
    "        return avg_lead\n",
    "\n",
    "    def single_map_func(self, dp, is_training):\n",
    "        \"\"\"Data augmentation function.\"\"\"\n",
    "        fname = dp['file_path']\n",
    "        label = dp['target']\n",
    "        try:\n",
    "            fname = fname.strip()\n",
    "            waves = np.load(fname)\n",
    "            # print(waves.shape)\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"=====fname====exception:\", fname, e)\n",
    "            waves = np.zeros(shape=[29, 2000])\n",
    "            label = 0\n",
    "\n",
    "        waves = self.norm(waves)\n",
    "\n",
    "        avg_lead = self.lead(waves)\n",
    "        # print('avg_lead', avg_lead.shape)\n",
    "\n",
    "        if is_training and random.uniform(0, 1) < 1.:\n",
    "            waves[:19, :] = self.xshuffle(waves[:19, :])\n",
    "            avg_lead = self.xshuffle(avg_lead)\n",
    "        print(\"1:\" , waves.shape, avg_lead.shape)\n",
    "        waves = np.concatenate([waves, avg_lead], axis=0)\n",
    "\n",
    "        label = np.expand_dims(label, -1)\n",
    "\n",
    "        C, L = waves.shape\n",
    "        print(\"2:\" , waves.shape)\n",
    "\n",
    "        if L < 2000:\n",
    "            waves = np.pad(waves, ((0, 0), (0, 2000 - L)), 'constant', constant_values=0)\n",
    "        elif L > 2000:\n",
    "            waves = waves[:, 2000]\n",
    "        waves = np.ascontiguousarray(waves)\n",
    "        # print(waves.shape)\n",
    "\n",
    "        return waves, label\n"
   ],
   "id": "464e51dd82cc1869",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T18:44:21.704256Z",
     "start_time": "2025-05-06T18:44:21.698347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class ROCAUCMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "\n",
    "        self.y_true_11 = None\n",
    "        self.y_pred_11 = None\n",
    "\n",
    "    def update(self, y_true, y_pred):\n",
    "        y_true = y_true.cpu().numpy()\n",
    "\n",
    "        y_pred = torch.sigmoid(y_pred).data.cpu().numpy()\n",
    "\n",
    "        if self.y_true_11 is None:\n",
    "            self.y_true_11 = y_true\n",
    "            self.y_pred_11 = y_pred\n",
    "        else:\n",
    "            self.y_true_11 = np.concatenate((self.y_true_11, y_true), axis=0)\n",
    "            self.y_pred_11 = np.concatenate((self.y_pred_11, y_pred), axis=0)\n",
    "\n",
    "        return self.y_true_11, self.y_pred_11\n",
    "\n",
    "    def fast_auc(self, y_true, y_prob):\n",
    "\n",
    "        y_true = np.asarray(y_true)\n",
    "        y_true = y_true[np.argsort(y_prob)]\n",
    "        cumfalses = np.cumsum(1 - y_true)\n",
    "        nfalse = cumfalses[-1]\n",
    "        auc = (y_true * cumfalses).sum()\n",
    "\n",
    "        auc /= (nfalse * (len(y_true) - nfalse))\n",
    "        return auc\n",
    "\n",
    "    @property\n",
    "    def avg(self):\n",
    "\n",
    "        self.y_true_11 = self.y_true_11.reshape(-1)\n",
    "        self.y_pred_11 = self.y_pred_11.reshape(-1)\n",
    "        score = self.fast_auc(self.y_true_11, self.y_pred_11)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def evaluate(y_true, y_pred, digits=4, cutoff='auto'):\n",
    "\n",
    "        if cutoff == 'auto':\n",
    "            fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "            youden = tpr - fpr\n",
    "            cutoff = thresholds[np.argmax(youden)]\n",
    "\n",
    "        return cutoff\n",
    "\n",
    "    def report(self):\n",
    "\n",
    "        self.y_true_11 = self.y_true_11.reshape(-1)\n",
    "        self.y_pred_11 = self.y_pred_11.reshape(-1)\n",
    "\n",
    "        for score in range(1, 20):\n",
    "            score = score / 20\n",
    "            y_pre = self.y_pred_11 > score\n",
    "\n",
    "            tn, fp, fn, tp = confusion_matrix(self.y_true_11, y_pre).ravel()\n",
    "\n",
    "            precision = precision_score(self.y_true_11, y_pre)\n",
    "            recall = recall_score(self.y_true_11, y_pre)\n",
    "            f1 = f1_score(self.y_true_11, y_pre)\n",
    "\n",
    "            print('for threshold: %.4f, tn: %d,fp: %d,fn: %d,tp: %d,precision: %.4f, '\n",
    "                  'recall: %.4f, f1: %.4f' % (score, tn, fp, fn, tp, precision, recall, f1))\n",
    "\n",
    "        return score\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "5ae1a8b020308a6b",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T18:44:21.907937Z",
     "start_time": "2025-05-06T18:44:21.898709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "class Train(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                 train_df,\n",
    "                 val_df,\n",
    "                 fold):\n",
    "        # print(train_df)\n",
    "        self.ddp = False\n",
    "        self.train_df = train_df\n",
    "\n",
    "        if self.ddp:\n",
    "            torch.distributed.init_process_group(backend=\"nccl\")\n",
    "            self.train_generator = AlaskaDataIter(train_df, training_flag=True, shuffle=False)\n",
    "            self.train_ds = DataLoader(self.train_generator,\n",
    "                                       config.TRAIN.batch_size,\n",
    "                                       num_workers=config.TRAIN.process_num,\n",
    "                                       sampler=DistributedSampler(self.train_generator,\n",
    "                                                                  shuffle=True))\n",
    "\n",
    "            self.val_generator = AlaskaDataIter(val_df, training_flag=False, shuffle=False)\n",
    "\n",
    "            self.val_ds = DataLoader(self.val_generator,\n",
    "                                     config.TRAIN.validatiojn_batch_size,\n",
    "                                     num_workers=config.TRAIN.process_num,\n",
    "                                     sampler=DistributedSampler(self.val_generator,\n",
    "                                                                shuffle=False))\n",
    "            local_rank = torch.distributed.get_rank()\n",
    "            torch.cuda.set_device(local_rank)\n",
    "            self.device = torch.device(\"cuda\", local_rank)\n",
    "\n",
    "\n",
    "        else:\n",
    "            self.train_generator = AlaskaDataIter(train_df, training_flag=True, shuffle=False)\n",
    "\n",
    "            self.train_ds = DataLoader(self.train_generator,\n",
    "                                       config.TRAIN.batch_size,\n",
    "                                       num_workers=config.TRAIN.process_num, shuffle=True)\n",
    "\n",
    "            self.val_generator = AlaskaDataIter(val_df, training_flag=False, shuffle=False)\n",
    "\n",
    "            self.val_ds = DataLoader(self.val_generator,\n",
    "                                     config.TRAIN.validatiojn_batch_size,\n",
    "                                     num_workers=config.TRAIN.process_num, shuffle=False)\n",
    "\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        self.fold = fold\n",
    "\n",
    "        self.init_lr = config.TRAIN.init_lr\n",
    "        self.warmup_step = config.TRAIN.warmup_step\n",
    "        self.epochs = config.TRAIN.epoch\n",
    "        self.batch_size = config.TRAIN.batch_size\n",
    "        self.l2_regularization = config.TRAIN.weight_decay_factor\n",
    "        self.early_stop = config.MODEL.early_stop\n",
    "        self.accumulation_step = config.TRAIN.accumulation_batch_size // config.TRAIN.batch_size\n",
    "        self.gradient_clip = config.TRAIN.gradient_clip\n",
    "        self.is_base = config.is_base\n",
    "        self.save_dir = config.MODEL.model_path\n",
    "        self.fp16 = config.TRAIN.mix_precision\n",
    "\n",
    "        channel_num = 0\n",
    "        self.model = Net(add_channel=channel_num).to(self.device)\n",
    "        self.load_weight()\n",
    "\n",
    "        if 'Adamw' in config.TRAIN.opt:\n",
    "            self.optimizer = torch.optim.AdamW(self.model.parameters(),\n",
    "                                               lr=self.init_lr, eps=1.e-5,\n",
    "                                               weight_decay=self.l2_regularization)\n",
    "        else:\n",
    "            self.optimizer = torch.optim.SGD(self.model.parameters(),\n",
    "                                             lr=self.init_lr,\n",
    "                                             momentum=0.9,\n",
    "                                             weight_decay=self.l2_regularization)\n",
    "\n",
    "        if self.ddp:\n",
    "            self.model = torch.nn.parallel.DistributedDataParallel(self.model,\n",
    "                                                                   device_ids=[local_rank],\n",
    "                                                                   output_device=local_rank,\n",
    "                                                                   find_unused_parameters=True)\n",
    "        else:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "\n",
    "        self.iter_num = 0\n",
    "\n",
    "        if config.TRAIN.lr_scheduler == 'cos':\n",
    "            logger.info('lr_scheduler.CosineAnnealingLR')\n",
    "            self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer,\n",
    "                                                                        self.epochs,\n",
    "                                                                        eta_min=1.e-7)\n",
    "        else:\n",
    "            logger.info('lr_scheduler.ReduceLROnPlateau')\n",
    "            self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer,\n",
    "                                                                        mode='max',\n",
    "                                                                        patience=5,\n",
    "                                                                        min_lr=1e-7,\n",
    "                                                                        factor=config.TRAIN.lr_scheduler_factor,\n",
    "                                                                        verbose=True)\n",
    "\n",
    "        self.criterion = BinaryCrossEntropy(smoothing=0.1, pos_weight=torch.tensor(2.)).to(self.device)\n",
    "\n",
    "        self.scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    def custom_loop(self):\n",
    "\n",
    "        def distributed_train_epoch(epoch_num):\n",
    "\n",
    "            summary_loss = AverageMeter()\n",
    "            rocauc_score = ROCAUCMeter()\n",
    "            self.model.train()\n",
    "\n",
    "            for images, label in self.train_ds:\n",
    "\n",
    "                if epoch_num < 10:\n",
    "                    # excute warm up in the first epochs\n",
    "                    if self.warmup_step > 0:\n",
    "                        if self.iter_num < self.warmup_step:\n",
    "                            for param_group in self.optimizer.param_groups:\n",
    "                                param_group['lr'] = self.iter_num / float(self.warmup_step) * self.init_lr\n",
    "                                lr = param_group['lr']\n",
    "\n",
    "                            logger.info('warm up with learning rate: [%f]' % (lr))\n",
    "\n",
    "                start = time.time()\n",
    "\n",
    "                data = images.to(self.device).float()\n",
    "                label = label.to(self.device).float()\n",
    "\n",
    "                batch_size = data.shape[0]\n",
    "\n",
    "                with torch.cuda.amp.autocast(enabled=self.fp16):\n",
    "                    predictions = self.model(data)\n",
    "                    current_loss = self.criterion(predictions, label)\n",
    "\n",
    "                summary_loss.update(current_loss.detach().item(), batch_size)\n",
    "                rocauc_score.update(label, predictions)\n",
    "                self.scaler.scale(current_loss).backward()\n",
    "\n",
    "                if ((self.iter_num + 1) % self.accumulation_step) == 0:\n",
    "                    self.scaler.unscale_(self.optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=self.gradient_clip, norm_type=2)\n",
    "                    self.scaler.step(self.optimizer)\n",
    "                    self.scaler.update()\n",
    "                    self.optimizer.zero_grad()\n",
    "\n",
    "                self.iter_num += 1\n",
    "                time_cost_per_batch = time.time() - start\n",
    "\n",
    "                images_per_sec = config.TRAIN.batch_size / time_cost_per_batch\n",
    "\n",
    "                if self.iter_num % config.TRAIN.log_interval == 0:\n",
    "                    log_message = '[fold %d], ' \\\n",
    "                                  'Train Step %d, ' \\\n",
    "                                  'summary_loss: %.6f, ' \\\n",
    "                                  'time: %.6f, ' \\\n",
    "                                  'speed %d images/persec' % (\n",
    "                                      self.fold,\n",
    "                                      self.iter_num,\n",
    "                                      summary_loss.avg,\n",
    "                                      time.time() - start,\n",
    "                                      images_per_sec)\n",
    "                    logger.info(log_message)\n",
    "\n",
    "            return summary_loss, rocauc_score\n",
    "\n",
    "        def distributed_test_epoch(epoch_num):\n",
    "\n",
    "            rocauc_score = ROCAUCMeter()\n",
    "            summary_loss = AverageMeter()\n",
    "            self.model.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for (images, labels) in tqdm(self.val_ds):\n",
    "                    data = images.to(self.device).float()\n",
    "                    labels = labels.to(self.device).float()\n",
    "\n",
    "                    batch_size = data.shape[0]\n",
    "\n",
    "                    predictions = self.model(data)\n",
    "                    current_loss = self.criterion(predictions, labels)\n",
    "\n",
    "                    rocauc_score.update(labels, predictions)\n",
    "                    summary_loss.update(current_loss.detach().item(), batch_size)\n",
    "\n",
    "            return rocauc_score, summary_loss\n",
    "\n",
    "        best_distance = 0.\n",
    "        not_improvement = 0\n",
    "        for epoch in range(self.epochs):\n",
    "\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                lr = param_group['lr']\n",
    "            logger.info('learning rate: [%f]' % (lr))\n",
    "            t = time.time()\n",
    "\n",
    "            summary_loss, roc_auc_score = distributed_train_epoch(epoch)\n",
    "            train_epoch_log_message = '[fold %d], ' \\\n",
    "                                      '[RESULT]: TRAIN. Epoch: %d,' \\\n",
    "                                      ' summary_loss: %.5f,' \\\n",
    "                                      ' time:%.5f' % (\n",
    "                                          self.fold,\n",
    "                                          epoch,\n",
    "                                          summary_loss.avg,\n",
    "                                          (time.time() - t))\n",
    "            logger.info(train_epoch_log_message)\n",
    "            roc_auc_score.report()\n",
    "\n",
    "            if epoch % config.TRAIN.test_interval == 0:\n",
    "                roc_auc_score, summary_loss = distributed_test_epoch(epoch)\n",
    "\n",
    "                val_epoch_log_message = '[fold %d], ' \\\n",
    "                                        '[RESULT]: VAL. Epoch: %d,' \\\n",
    "                                        ' val_loss: %.5f,' \\\n",
    "                                        ' val_roc_auc: %.5f,' \\\n",
    "                                        ' time:%.5f' % (\n",
    "                                            self.fold,\n",
    "                                            epoch,\n",
    "                                            summary_loss.avg,\n",
    "                                            roc_auc_score.avg,\n",
    "                                            (time.time() - t))\n",
    "                logger.info(val_epoch_log_message)\n",
    "                roc_auc_score.report()\n",
    "\n",
    "            if config.TRAIN.lr_scheduler == 'cos':\n",
    "                self.scheduler.step()\n",
    "            else:\n",
    "                self.scheduler.step(roc_auc_score.avg)\n",
    "\n",
    "            # save model\n",
    "            if not os.access(config.MODEL.model_path, os.F_OK):\n",
    "                os.mkdir(config.MODEL.model_path)\n",
    "\n",
    "            #### save the model every end of epoch\n",
    "            current_model_saved_name = self.save_dir + '/fold%d_epoch_%d_val_rocauc_%.6f_loss_%.6f.pth' % (self.fold,\n",
    "                                                                                                           epoch,\n",
    "                                                                                                           roc_auc_score.avg,\n",
    "                                                                                                           summary_loss.avg)\n",
    "\n",
    "            logger.info('A model saved to %s' % current_model_saved_name)\n",
    "            torch.save(self.model.module.state_dict(), current_model_saved_name)\n",
    "\n",
    "            if summary_loss.avg < best_distance:\n",
    "                best_distance = summary_loss.avg\n",
    "                logger.info(' best loss value update as %.6f' % (best_distance))\n",
    "                logger.info(' bestmodel update as %s' % (current_model_saved_name))\n",
    "                not_improvement = 0\n",
    "\n",
    "            else:\n",
    "                not_improvement += 1\n",
    "\n",
    "            if not_improvement >= self.early_stop:\n",
    "                logger.info(' best metric score not improvement for %d, break' % (self.early_stop))\n",
    "                break\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    def load_weight(self):\n",
    "        if config.MODEL.pretrained_model is not None:\n",
    "            state_dict = torch.load(config.MODEL.pretrained_model, map_location=self.device)\n",
    "            self.model.load_state_dict(state_dict, strict=False)\n"
   ],
   "id": "8f3f3fc75163b737",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T18:44:22.088259Z",
     "start_time": "2025-05-06T18:44:22.068442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_fold = 5\n",
    "\n",
    "\n",
    "def get_fold(n_fold=n_fold):\n",
    "    data = pd.read_csv(config.DATA.data_file)\n",
    "\n",
    "    folds = data.copy()\n",
    "    Fold = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=config.SEED)\n",
    "    for n, (train_index, val_index) in enumerate(Fold.split(folds, folds['target'])):\n",
    "        folds.loc[val_index, 'fold'] = int(n)\n",
    "    return folds\n",
    "\n",
    "\n",
    "data = get_fold(n_fold)\n",
    "print(data.columns)\n",
    "data.head()\n",
    "\n",
    "\n"
   ],
   "id": "3082d89031b9bec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['file_path', 'target', 'train_val', 'fold'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                           file_path  target  train_val  fold\n",
       "0  /run/media/kami/SSD/DATASETS/vepiset-dataset/N...       0          0   1.0\n",
       "1  /run/media/kami/SSD/DATASETS/vepiset-dataset/N...       0          0   0.0\n",
       "2  /run/media/kami/SSD/DATASETS/vepiset-dataset/N...       0          0   3.0\n",
       "3  /run/media/kami/SSD/DATASETS/vepiset-dataset/N...       0          0   3.0\n",
       "4  /run/media/kami/SSD/DATASETS/vepiset-dataset/N...       0          0   0.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>target</th>\n",
       "      <th>train_val</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/run/media/kami/SSD/DATASETS/vepiset-dataset/N...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/run/media/kami/SSD/DATASETS/vepiset-dataset/N...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/run/media/kami/SSD/DATASETS/vepiset-dataset/N...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/run/media/kami/SSD/DATASETS/vepiset-dataset/N...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/run/media/kami/SSD/DATASETS/vepiset-dataset/N...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T18:44:34.077915Z",
     "start_time": "2025-05-06T18:44:33.012700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gc\n",
    "del trainer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n",
    "for fold in range(1):\n",
    "    ###build dataset\n",
    "\n",
    "    train_ind = data[data['train_val'] == 0].index.values\n",
    "    train_data = data.iloc[train_ind].copy()\n",
    "    val_ind = data[data['train_val'] == 1].index.values\n",
    "    val_data = data.iloc[val_ind].copy()\n",
    "    trainer = Train(train_df=train_data,\n",
    "                    val_df=val_data,\n",
    "                    fold=fold)\n",
    "    print(trainer.train_generator[100][0].shape)\n",
    "    print(trainer.train_generator[100][0][0])\n",
    "    print(trainer.val_generator[100][0].shape)\n",
    "    print(trainer.val_generator[100][0][0])\n",
    "    break\n",
    "\n",
    "    ### train\n",
    "    trainer.custom_loop()\n",
    "\n"
   ],
   "id": "2122aecc5c4b0d45",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-06 22:14:33,107] [INFO]  contains20360 samples  1979 pos \n",
      "[2025-05-06 22:14:33,107] [INFO]  contains20360 samples \n",
      "[2025-05-06 22:14:33,108] [INFO]  After filter contains20360 samples  1979 pos \n",
      "[2025-05-06 22:14:33,108] [INFO]  After filter contains20360 samples \n",
      "[2025-05-06 22:14:33,108] [INFO]  contains5089 samples  537 pos \n",
      "[2025-05-06 22:14:33,108] [INFO]  contains5089 samples \n",
      "[2025-05-06 22:14:33,108] [INFO]  After filter contains5089 samples  537 pos \n",
      "[2025-05-06 22:14:33,109] [INFO]  After filter contains5089 samples \n",
      "[2025-05-06 22:14:33,732] [INFO] Loading pretrained weights from Hugging Face hub (timm/vgg16.tv_in1k) \n",
      "[2025-05-06 22:14:33,991] [INFO] [timm/vgg16.tv_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors. \n",
      "[2025-05-06 22:14:33,992] [INFO] Converted input conv features.0 pretrained weights from 3 to 45 channel(s) \n",
      "[2025-05-06 22:14:34,074] [INFO] lr_scheduler.CosineAnnealingLR \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: (26, 2000) (19, 2000)\n",
      "2: (45, 2000)\n",
      "(45, 2000)\n",
      "1: (26, 2000) (19, 2000)\n",
      "2: (45, 2000)\n",
      "[-0.20503941 -0.20876394 -0.20465516 ...  0.02297692  0.02346165\n",
      "  0.0214775 ]\n",
      "1: (26, 2000) (19, 2000)\n",
      "2: (45, 2000)\n",
      "(45, 2000)\n",
      "1: (26, 2000) (19, 2000)\n",
      "2: (45, 2000)\n",
      "[-0.74088866 -0.7457651  -0.76338035 ...  0.49662745  0.48058847\n",
      "  0.46136445]\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. Validation",
   "id": "4f4b431f6d1a590d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T18:41:48.547870Z",
     "start_time": "2025-05-06T18:41:48.542985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_data_iter(test_path=config.DATA.data_file):\n",
    "    data = pd.read_csv(test_path)\n",
    "\n",
    "    val_ind = data[data['train_val'] == 1].index.values\n",
    "    val_data = data.iloc[val_ind].copy()\n",
    "\n",
    "    valds = AlaskaDataIter(val_data, training_flag=False, shuffle=False)\n",
    "    valds = DataLoader(valds,\n",
    "                       32,\n",
    "                       num_workers=2,\n",
    "                       shuffle=False)\n",
    "    return valds\n",
    "\n",
    "\n",
    "def get_model(weight, device, is_base=0):\n",
    "    channel_num = 0\n",
    "    if is_base == 0:\n",
    "        channel_num = 128\n",
    "    model = Net(add_channel=channel_num).to(device)\n",
    "    state_dict = torch.load(weight, map_location=device)\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def eval_add_plt(weight_video, weight_base, test_path):\n",
    "    rocauc_score = ROCAUCMeter()\n",
    "\n",
    "    base_y_true, base_y_pre = estimated_score(weight_base, test_path, 1)\n",
    "    video_y_true, video_y_pre = estimated_score(weight_video, test_path, 0)\n",
    "\n",
    "    print(\"========= estimated_score base line  ==========\", test_path)\n",
    "    rocauc_score.report_with_recall_precision(base_y_true, base_y_pre)\n",
    "    #rocauc_score.report_all(base_y_true, base_y_pre)\n",
    "\n",
    "    print(\"========= estimated_score add video ==========\", test_path)\n",
    "    rocauc_score.report_with_recall_precision(video_y_true, video_y_pre)\n",
    "    #rocauc_score.report_all(video_y_true, video_y_pre)\n",
    "\n",
    "    print(\"========= precision_recall ==========\", test_path)\n",
    "    img_path_p_r = test_path.split(\".\")[0] + \"_Precision_Recall__Add_Data_Pre\" + \".jpg\"\n",
    "    rocauc_score.report_with_recall(video_y_true, video_y_pre, base_y_true, base_y_pre, img_path_p_r)\n",
    "\n",
    "    print(\"========= Specificity_Sensitivity ==========\", test_path)\n",
    "    img_path_t_f = test_path.split(\".\")[0] + \"_Specificity_Sensitivity__Add_Data_Pre\" + \".jpg\"\n",
    "    rocauc_score.report_tpr_fpr(video_y_true, video_y_pre, base_y_true, base_y_pre, img_path_t_f)\n",
    "\n",
    "\n",
    "def estimated_score(weight, test_path, is_base):\n",
    "    # print(\"========= estimated_score test_path ==========\", test_path)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "    rocauc_score = ROCAUCMeter()\n",
    "    model = get_model(weight, device, is_base)\n",
    "    val_ds = get_data_iter(test_path)\n",
    "\n",
    "    labels_list = []\n",
    "    y_pre_list = []\n",
    "\n",
    "    y_true_11 = None\n",
    "    y_pred_11 = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(\"val_ds:\", val_ds)\n",
    "        for (images, labels, video_feature) in tqdm(val_ds):\n",
    "            data = images.to(device).float()\n",
    "            labels = labels.to(device).float()\n",
    "            labels_list.append(labels)\n",
    "            # base_feature = base_feature.to(device).float()\n",
    "            video_feature = video_feature.to(device).float()\n",
    "            batch_size = data.shape[0]\n",
    "            predictions = model(data, video_feature, is_base)\n",
    "            y_pre_list.append(predictions)\n",
    "            y_true_11, y_pred_11 = rocauc_score.update(labels, predictions)\n",
    "            #print(\"=====y_true_11=====\", y_true_11)\n",
    "            #print(\"=====y_pred_11=====\", y_pred_11)\n",
    "    # save labels_list and y_pre_list\n",
    "    labels_data = torch.cat(labels_list, dim=0)\n",
    "    y_pre_data = torch.cat(y_pre_list, dim=0)\n",
    "    print(\"labels len:\", len(labels_data.tolist()))\n",
    "    print(\"predictions len:\", len(y_pre_data.tolist()))\n",
    "\n",
    "    return y_true_11, y_pred_11\n",
    "\n",
    "\n",
    "def eval(weight, test_path):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "    rocauc_score = ROCAUCMeter()\n",
    "    model = get_model(weight, device)\n",
    "    val_ds = get_data_iter(test_path)\n",
    "\n",
    "    labels_list = []\n",
    "    y_pre_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(\"val_ds:\", val_ds)\n",
    "        for (images, labels) in tqdm(val_ds):\n",
    "            data = images.to(device).float()\n",
    "            labels = labels.to(device).float()\n",
    "\n",
    "            labels_list.append(labels)\n",
    "            # batch_size = data.shape[0]\n",
    "            predictions = model(data)\n",
    "            # intermediate_output = model.intermediate_layer(data)\n",
    "            y_pre_list.append(predictions)\n",
    "            rocauc_score.update(labels, predictions)\n",
    "\n",
    "        labels_data = torch.cat(labels_list, dim=0)\n",
    "        y_pre_data = torch.cat(y_pre_list, dim=0)\n",
    "        rocauc_score.report()\n",
    "\n",
    "    print(\"labels len:\", len(labels_data.tolist()))\n",
    "    print(\"predictions len:\", len(y_pre_data.tolist()))\n",
    "\n",
    "    return rocauc_score\n",
    "\n",
    "\n"
   ],
   "id": "32eeedc553d6f049",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T18:41:55.493359Z",
     "start_time": "2025-05-06T18:41:48.590978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weight = os.path.join(config.MODEL.model_path, \"fold0_epoch_0_val_rocauc_0.920773_loss_0.298342.pth\")\n",
    "# test_path = \"/run/media/kami/SSD/DATASETS/vepiset-dataset/CSV-Files/data.csv\"\n",
    "test_path = config.DATA.data_file\n",
    "try:\n",
    "    eval(weight, test_path)\n",
    "except Exception as e:\n",
    "    print(\"=====e=====\", e)\n"
   ],
   "id": "a69be3fe5f91ea12",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-06 22:11:49,256] [INFO] Loading pretrained weights from Hugging Face hub (timm/vgg16.tv_in1k) \n",
      "[2025-05-06 22:11:49,506] [INFO] [timm/vgg16.tv_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors. \n",
      "[2025-05-06 22:11:49,507] [INFO] Converted input conv features.0 pretrained weights from 3 to 45 channel(s) \n",
      "[2025-05-06 22:11:49,851] [INFO]  contains5089 samples  537 pos \n",
      "[2025-05-06 22:11:49,851] [INFO]  contains5089 samples \n",
      "[2025-05-06 22:11:49,851] [INFO]  After filter contains5089 samples  537 pos \n",
      "[2025-05-06 22:11:49,851] [INFO]  After filter contains5089 samples \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_ds: <torch.utils.data.dataloader.DataLoader object at 0x7c62ebd6acf0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/160 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead (19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000)\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000)\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead (19, 2000)avg_lead"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/160 [00:00<00:19,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000)\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)\n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000)\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5/160 [00:00<00:07, 21.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_lead avg_lead(19, 2000)\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 500) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)\n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000)\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) (19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) (19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead (19, 2000) (19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)\n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 9/160 [00:00<00:06, 24.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000)\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)\n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) (19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)\n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 1000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) (19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)\n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) (19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 13/160 [00:00<00:05, 26.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) (19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)\n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)\n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead (19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000)\n",
      " (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead (19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_leadavg_lead "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 17/160 [00:00<00:05, 26.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000)\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)avg_lead \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000)\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)\n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000)\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 1500)\n",
      "avg_lead (19, 2000)avg_lead \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 21/160 [00:00<00:05, 27.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead (19, 2000)(19, 2000)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 92/160 [00:03<00:02, 28.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) (19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 1000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead (19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000)\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) (19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 95/160 [00:03<00:02, 28.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) (19, 2000)\n",
      "\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000)\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000)\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) (19, 2000)\n",
      "\n",
      "avg_leadavg_lead (19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000)\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) (19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)\n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 99/160 [00:03<00:02, 28.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000)\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000)\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)\n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead (19, 2000) (19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead (19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000)\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) (19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)\n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 103/160 [00:03<00:02, 28.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) (19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) (19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead (19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) (19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)\n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)\n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)\n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 1000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)\n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 107/160 [00:03<00:01, 28.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead (19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead (19, 2000)\n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead (19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000)\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) (19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 111/160 [00:03<00:01, 28.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)\n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 500)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)\n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000)\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)\n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)avg_lead \n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)\n",
      "(19, 2000)\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_lead avg_lead(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead \n",
      "(19, 2000)\n",
      "avg_lead avg_lead (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)\n",
      "(19, 2000)\n",
      "avg_lead (19, 2000)\n",
      "avg_lead (19, 2000)avg_lead\n",
      " (19, 2000)\n",
      "avg_lead avg_lead (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead  (19, 2000)(19, 2000)\n",
      "\n",
      "avg_leadavg_lead "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 115/160 [00:04<00:01, 28.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 2000) \n",
      "(19, 2000)\n",
      "avg_lead avg_lead"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T18:41:55.526001Z",
     "start_time": "2025-05-06T18:41:55.524836Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ba1710b6c17b9ea2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f18a0d3b611b0819"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
